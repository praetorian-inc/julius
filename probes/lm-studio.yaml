# probes/lm-studio.yaml
# Reference: https://lmstudio.ai/docs/api/server
name: lm-studio
description: LM Studio local server
category: self-hosted
port_hint: 1234
specificity: 70
api_docs: https://lmstudio.ai/docs/api/server

requests:
  # LM Studio-specific: /api/v0/models endpoint (unique to LM Studio)
  - type: http
    path: /api/v0/models
    method: GET
    match:
      - type: status
        value: 200
      - type: body.contains
        value: '"object"'
      - type: body.contains
        value: '"data"'
      - type: body.contains
        not: true
        value: "<!DOCTYPE"
      - type: body.contains
        not: true
        value: "<html"

models:
  path: /v1/models
  method: GET
  extract: ".data[].id"

augustus:
  generator: openai
  config_template:
    endpoint: "$TARGET/v1"
    model: "$MODEL"
    api_key: "not-needed"
    timeout: 180
